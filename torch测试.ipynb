{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6211730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cfdf589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GHM_Loss(nn.Module):\n",
    "    def __init__(self, bins=10, alpha=0.5):\n",
    "        '''\n",
    "        bins: split to n bins\n",
    "        alpha: hyper-parameter\n",
    "        '''\n",
    "        super(GHM_Loss, self).__init__()\n",
    "        self._bins = bins\n",
    "        self._alpha = alpha\n",
    "        self._last_bin_count = None\n",
    "\n",
    "    def _g2bin(self, g):\n",
    "        return torch.floor(g * (self._bins - 0.0001)).long()\n",
    "\n",
    "    def _custom_loss(self, x, target, weight):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _custom_loss_grad(self, x, target):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        g = torch.abs(self._custom_loss_grad(x, target)).detach()\n",
    "        print(\"g\", g)\n",
    "        bin_idx = self._g2bin(g)\n",
    "        print(\"bin_idx\", bin_idx)\n",
    "        bin_count = torch.zeros((self._bins))\n",
    "        print(\"bin_count\", bin_count)\n",
    "        print(\"循环开始\")\n",
    "        for i in range(self._bins):\n",
    "            print((bin_idx == i))\n",
    "            print((bin_idx == i).sum())\n",
    "            bin_count[i] = (bin_idx == i).sum().item()\n",
    "            print(\"bin_count\", bin_count, i)\n",
    "        print(\"循环结束\")\n",
    "        N = (x.size(0) * x.size(1))\n",
    "        print(\"行\", x.size(0))\n",
    "        print(\"列\", x.size(1))\n",
    "        print(\"N\", N)\n",
    "        if self._last_bin_count is None:\n",
    "            self._last_bin_count = bin_count\n",
    "        else:\n",
    "            bin_count = self._alpha * self._last_bin_count + (1 - self._alpha) * bin_count\n",
    "            self._last_bin_count = bin_count\n",
    "        print(\"bin_count _last_bin_count\", bin_count, self._last_bin_count)\n",
    "        nonempty_bins = (bin_count > 0).sum().item()\n",
    "        print(\"nonempty_bins\", nonempty_bins)\n",
    "        gd = bin_count * nonempty_bins\n",
    "        print(\"gd\", gd)\n",
    "        gd = torch.clamp(gd, min=0.0001)\n",
    "        print(\"gd\", gd)\n",
    "        beta = N / gd\n",
    "        print(\"beta\", beta)\n",
    "        return self._custom_loss(x, target, beta[bin_idx])\n",
    "\n",
    "\n",
    "class GHMC_Loss(GHM_Loss):\n",
    "    '''\n",
    "        GHM_Loss for classification\n",
    "    '''\n",
    "\n",
    "    def __init__(self, bins, alpha):\n",
    "        super(GHMC_Loss, self).__init__(bins, alpha)\n",
    "\n",
    "    def _custom_loss(self, x, target, weight):\n",
    "        print(x.shape)\n",
    "        print(target.shape)\n",
    "        print(weight.shape)\n",
    "        return F.binary_cross_entropy_with_logits(x, target, weight=weight)\n",
    "\n",
    "    def _custom_loss_grad(self, x, target):\n",
    "        return torch.sigmoid(x).detach() - target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38430e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 5)\n",
    "target = torch.LongTensor(3, 1).random_(5)\n",
    "target = torch.zeros(3, 5).scatter_(1, target, 1)\n",
    "ghmc = GHMC_Loss(10, 0.5)\n",
    "result = ghmc.forward(x, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00dc2cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2240,  0.5549],\n",
      "        [-1.1436, -0.0177],\n",
      "        [ 0.0555, -0.1390]])\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "tensor([2.8617, 0.4143])\n",
      "tensor(1.2519)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(3, 2)\n",
    "target = torch.tensor([0, 1, 1])\n",
    "target = F.one_hot(target).float()\n",
    "print(input)\n",
    "print(target)\n",
    "weight_CE = torch.FloatTensor([1, 2, 3])\n",
    "weight_CE = torch.randn(2)\n",
    "print(weight_CE)\n",
    "ce = nn.CrossEntropyLoss(weight=weight_CE)\n",
    "    # ce = nn.CrossEntropyLoss()\n",
    "loss = ce(input, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d197939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BinaryDiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ignore_index: Specifies a target value that is ignored and does not contribute to the input gradient\n",
    "        reduction: Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'\n",
    "    Shapes:\n",
    "        output: A tensor of shape [N, *] without sigmoid activation function applied\n",
    "        target: A tensor of shape same with output\n",
    "    Returns:\n",
    "        Loss tensor according to arg reduction\n",
    "    Raise:\n",
    "        Exception if unexpected reduction\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ignore_index=None, reduction='mean', **kwargs):\n",
    "        super(BinaryDiceLoss, self).__init__()\n",
    "        self.smooth = 1  # suggest set a large number when target area is large,like '10|100'\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduction = reduction\n",
    "        self.batch_dice = False  # treat a large map when True\n",
    "        if 'batch_loss' in kwargs.keys():\n",
    "            self.batch_dice = kwargs['batch_loss']\n",
    "\n",
    "    def forward(self, output, target, use_sigmoid=True):\n",
    "        assert output.shape[0] == target.shape[0], \"output & target batch size don't match\"\n",
    "        if use_sigmoid:\n",
    "            output = torch.sigmoid(output)\n",
    "\n",
    "        if self.ignore_index is not None:\n",
    "            validmask = (target != self.ignore_index).float()\n",
    "            output = output.mul(validmask)  # can not use inplace for bp\n",
    "            target = target.float().mul(validmask)\n",
    "\n",
    "        dim0 = output.shape[0]\n",
    "        if self.batch_dice:\n",
    "            dim0 = 1\n",
    "\n",
    "        output = output.contiguous().view(dim0, -1)\n",
    "        target = target.contiguous().view(dim0, -1).float()\n",
    "\n",
    "        num = 2 * torch.sum(torch.mul(output, target), dim=1) + self.smooth\n",
    "        den = torch.sum(output.abs() + target.abs(), dim=1) + self.smooth\n",
    "\n",
    "        loss = 1 - (num / den)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        elif self.reduction == 'none':\n",
    "            return loss\n",
    "        else:\n",
    "            raise Exception('Unexpected reduction {}'.format(self.reduction))\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        weight: An array of shape [num_classes,]\n",
    "        ignore_index: Specifies a target value that is ignored and does not contribute to the input gradient\n",
    "        output: A tensor of shape [N, C, *]\n",
    "        target: A tensor of same shape with output\n",
    "        other args pass to BinaryDiceLoss\n",
    "    Return:\n",
    "        same as BinaryDiceLoss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weight=None, ignore_index=None, **kwargs):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.kwargs = kwargs\n",
    "        self.weight = weight\n",
    "        if isinstance(ignore_index, (int, float)):\n",
    "            self.ignore_index = [int(ignore_index)]\n",
    "        elif ignore_index is None:\n",
    "            self.ignore_index = []\n",
    "        elif isinstance(ignore_index, (list, tuple)):\n",
    "            self.ignore_index = ignore_index\n",
    "        else:\n",
    "            raise TypeError(\"Expect 'int|float|list|tuple', while get '{}'\".format(type(ignore_index)))\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        assert output.shape == target.shape, 'output & target shape do not match'\n",
    "        dice = BinaryDiceLoss(**self.kwargs)\n",
    "        total_loss = 0\n",
    "        output = F.softmax(output, dim=1)\n",
    "        for i in range(target.shape[1]):\n",
    "            if i not in self.ignore_index:\n",
    "                dice_loss = dice(output[:, i], target[:, i], use_sigmoid=False)\n",
    "                if self.weight is not None:\n",
    "                    assert self.weight.shape[0] == target.shape[1], \\\n",
    "                        'Expect weight shape [{}], get[{}]'.format(target.shape[1], self.weight.shape[0])\n",
    "                    dice_loss *= self.weights[i]\n",
    "                total_loss += (dice_loss)\n",
    "        loss = total_loss / (target.size(1) - len(self.ignore_index))\n",
    "        return loss\n",
    "\n",
    "\n",
    "def test():\n",
    "    input = torch.rand((3, 1, 32, 32, 32))\n",
    "    model = nn.Conv3d(1, 4, 3, padding=1)\n",
    "    target = torch.randint(0, 4, (3, 1, 32, 32, 32)).float()\n",
    "    target = make_one_hot(target, num_classes=4)\n",
    "    criterion = DiceLoss(ignore_index=[2, 3], reduction='mean')\n",
    "    loss = criterion(model(input), target)\n",
    "    loss.backward()\n",
    "    print(loss.item())\n",
    "\n",
    "\n",
    "def make_one_hot(input, num_classes=None):\n",
    "    \"\"\"Convert class index tensor to one hot encoding tensor.\n",
    "\n",
    "    Args:\n",
    "         input: A tensor of shape [N, 1, *]\n",
    "         num_classes: An int of number of class\n",
    "    Shapes:\n",
    "        predict: A tensor of shape [N, *] without sigmoid activation function applied\n",
    "        target: A tensor of shape same with predict\n",
    "    Returns:\n",
    "        A tensor of shape [N, num_classes, *]\n",
    "    \"\"\"\n",
    "    if num_classes is None:\n",
    "        num_classes = input.max() + 1\n",
    "    shape = np.array(input.shape)\n",
    "    shape[1] = num_classes\n",
    "    shape = tuple(shape)\n",
    "    result = torch.zeros(shape)\n",
    "    result = result.scatter_(1, input.cpu().long(), 1)\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db6899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDiceLoss(nn.Module):\n",
    "    \"\"\"DiceLoss implemented from 'Dice Loss for Data-imbalanced NLP Tasks'\n",
    "    Useful in dealing with unbalanced data\n",
    "    Add softmax automatically\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=0.5, gamma=0.5):\n",
    "        super(BinaryDiceLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, y_pred, y_true, reduction='mean'):\n",
    "        \"\"\"\n",
    "        :param y_pred: [N, C, ]\n",
    "        :param y_true: [N, C, ]\n",
    "        :param reduction: 'mean' or 'sum'\n",
    "        \"\"\"\n",
    "        batch_size = y_true.size(0)\n",
    "        y_pred = y_pred.contiguous().view(batch_size, -1)\n",
    "        y_true = y_true.contiguous().view(batch_size, -1)\n",
    "        \n",
    "        # 分子\n",
    "        numerator = torch.sum(2 * torch.pow((1 - y_pred), self.alpha) * y_pred * y_true, dim=1) + self.gamma\n",
    "        denominator = torch.sum(torch.pow((1 - y_pred), self.alpha)  * y_pred + y_true, dim=1) + self.gamma\n",
    "        loss = 1 - (numerator / denominator)\n",
    "        if reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=1):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.binary_dice_loss = BinaryDiceLoss(alpha, gamma)\n",
    "\n",
    "    def forward(self, y_pred, y_true, reduction='mean'):\n",
    "        \"\"\"\n",
    "        :param y_pred: [N, C, ]\n",
    "        :param y_true: [N, ]\n",
    "        :param reduction: 'mean' or 'sum'\n",
    "        \"\"\"\n",
    "        shape = y_pred.shape\n",
    "        num_labels = shape[1]\n",
    "        dims = [i for i in range(len(y_pred.shape))]\n",
    "        dims.insert(1, dims.pop())\n",
    "        y_pred = torch.softmax(y_pred, dim=1)\n",
    "        y_true = F.one_hot(y_true, num_classes=num_labels).permute(*dims)\n",
    "        loss = self.binary_dice_loss(y_pred, y_true, reduction)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386c016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cddadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c837702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a703a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3369dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2dac1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea297ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7293b7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1643cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c2169e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226b410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff434281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1c847b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5232932f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcebac3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dacf16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fd5b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5589eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f4f00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058238b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c38dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4a728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2c76f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81729c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c189a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cfe971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de1708d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b85e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed7f482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5388c295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f19e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa3c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204206a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c32bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f461cc52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d57068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8ff18a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71596ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbb45a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
