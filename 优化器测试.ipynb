{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "775f1e37",
   "metadata": {},
   "source": [
    "## 代码重复部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "177990b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DN\\anaconda3\\envs\\python36\\lib\\site-packages\\numpy\\__init__.py:138: UserWarning: mkl-service package failed to import, therefore Intel(R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see http://github.com/IntelPython/mkl-service\n",
      "  from . import _distributor_init\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "import torch.utils.data as Data\n",
    " \n",
    "torch.manual_seed(1)  # 设置随机种子, 用于复现\n",
    " \n",
    "# 超参数\n",
    "EPOCH = 1       # 前向后向传播迭代次数\n",
    "LR = 0.001      # 学习率 learning rate \n",
    "BATCH_SIZE = 50 # 批量训练时候一次送入数据的size\n",
    "DOWNLOAD_MNIST = True \n",
    " \n",
    "# 下载mnist手写数据集\n",
    "# 训练集\n",
    "train_data = torchvision.datasets.MNIST(  \n",
    "    root = './MNIST/',                      \n",
    "    train = True,                            \n",
    "    transform = torchvision.transforms.ToTensor(),                                                \n",
    "    download=DOWNLOAD_MNIST \n",
    ")\n",
    " \n",
    "# 测试集\n",
    "test_data = torchvision.datasets.MNIST(root='./MNIST/', train=False)  # train设置为False表示获取测试集\n",
    " \n",
    "# 一个批训练 50个样本, 1 channel通道, 图片尺寸 28x28 size:(50, 1, 28, 28)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ") \n",
    "#  测试数据预处理；只测试前2000个\n",
    "test_x = torch.unsqueeze(test_data.data,dim=1).float()[:2000] / 255.0\n",
    "# shape from (2000, 28, 28) to (2000, 1, 28, 28)\n",
    "test_y = test_data.targets[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da1051",
   "metadata": {},
   "source": [
    "## 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16307a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    " \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(                      # 输入的图片 （1，28，28）\n",
    "                in_channels=1,\n",
    "                out_channels=16,            # 经过一个卷积层之后 （16,28,28）\n",
    "                kernel_size=5,\n",
    "                stride=1,                    # 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)      # 经过池化层处理，维度为（16,14,14）\n",
    "        )\n",
    " \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(                         # 输入（16,14,14）\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),                                 # 输出（32,14,14）\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)        # 输出（32,7,7）\n",
    "        )\n",
    " \n",
    "        self.out = nn.Linear(32*7*7,10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)                     #（batch_size,16,14,14）\n",
    "        x = self.conv2(x)                     # 输出（batch_size,32,7,7）\n",
    "        x = x.view(x.size(0),-1)              # (batch_size,32*7*7)\n",
    "        out = self.out(x)                     # (batch_size,10)\n",
    "        return out\n",
    " \n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea0dc1",
   "metadata": {},
   "source": [
    "## Adam 原代码也是常用优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a608176c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.0219\n",
      "Epoch:  0 | train loss: 0.0763\n",
      "Epoch:  0 | train loss: 0.0519\n",
      "Epoch:  0 | train loss: 0.0490\n",
      "Epoch:  0 | train loss: 0.0113\n",
      "Epoch:  0 | train loss: 0.0628\n",
      "Epoch:  0 | train loss: 0.0354\n",
      "Epoch:  0 | train loss: 0.0361\n",
      "Epoch:  0 | train loss: 0.2080\n",
      "Epoch:  0 | train loss: 0.0424\n",
      "Epoch:  0 | train loss: 0.0497\n",
      "Epoch:  0 | train loss: 0.0305\n",
      "Epoch:  0 | train loss: 0.0716\n",
      "Epoch:  0 | train loss: 0.0401\n",
      "Epoch:  0 | train loss: 0.0052\n",
      "Epoch:  0 | train loss: 0.0431\n",
      "Epoch:  0 | train loss: 0.0015\n",
      "Epoch:  0 | train loss: 0.0311\n",
      "Epoch:  0 | train loss: 0.0341\n",
      "Epoch:  0 | train loss: 0.0399\n",
      "Epoch:  0 | train loss: 0.0017\n",
      "Epoch:  0 | train loss: 0.0269\n",
      "Epoch:  0 | train loss: 0.0291\n",
      "Epoch:  0 | train loss: 0.0261\n",
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(),lr=LR) # 定义优化器\n",
    "loss_func = nn.CrossEntropyLoss() # 定义损失函数\n",
    " \n",
    "for epoch in range(EPOCH):\n",
    " \n",
    "    for step,(batch_x,batch_y) in enumerate(train_loader):\n",
    "        pred_y = cnn(batch_x)\n",
    "        loss = loss_func(pred_y,batch_y)\n",
    "        optimizer.zero_grad() # 清空上一层梯度\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新优化器的学习率，一般按照epoch为单位进行更新\n",
    " \n",
    "        if step % 50 == 0:\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].numpy()  # torch.max(test_out,1)返回的是test_out中每一行最大的数)\n",
    "                                                                # 返回的形式为torch.return_types.max(\n",
    "                                                                #           values=tensor([0.7000, 0.9000]),\n",
    "                                                                #           indices=tensor([2, 2]))\n",
    "                                                                # 后面的[1]代表获取indices\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n",
    " \n",
    " \n",
    "# 打印前十个测试结果和真实结果进行对比\n",
    "test_output = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc0c845",
   "metadata": {},
   "source": [
    "## SGD部分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d34cb5",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f94767db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.0358\n",
      "Epoch:  0 | train loss: 0.0203\n",
      "Epoch:  0 | train loss: 0.0930\n",
      "Epoch:  0 | train loss: 0.0050\n",
      "Epoch:  0 | train loss: 0.0183\n",
      "Epoch:  0 | train loss: 0.0031\n",
      "Epoch:  0 | train loss: 0.0385\n",
      "Epoch:  0 | train loss: 0.0474\n",
      "Epoch:  0 | train loss: 0.0311\n",
      "Epoch:  0 | train loss: 0.0766\n",
      "Epoch:  0 | train loss: 0.0707\n",
      "Epoch:  0 | train loss: 0.0133\n",
      "Epoch:  0 | train loss: 0.0020\n",
      "Epoch:  0 | train loss: 0.1394\n",
      "Epoch:  0 | train loss: 0.0339\n",
      "Epoch:  0 | train loss: 0.0578\n",
      "Epoch:  0 | train loss: 0.1446\n",
      "Epoch:  0 | train loss: 0.0105\n",
      "Epoch:  0 | train loss: 0.0718\n",
      "Epoch:  0 | train loss: 0.0155\n",
      "Epoch:  0 | train loss: 0.0072\n",
      "Epoch:  0 | train loss: 0.0538\n",
      "Epoch:  0 | train loss: 0.0438\n",
      "Epoch:  0 | train loss: 0.0042\n",
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(cnn.parameters(),lr=LR) # 定义优化器\n",
    "loss_func = nn.CrossEntropyLoss() # 定义损失函数\n",
    " \n",
    "for epoch in range(EPOCH):\n",
    " \n",
    "    for step,(batch_x,batch_y) in enumerate(train_loader):\n",
    "        pred_y = cnn(batch_x)\n",
    "        loss = loss_func(pred_y,batch_y)\n",
    "        optimizer.zero_grad() # 清空上一层梯度\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新优化器的学习率，一般按照epoch为单位进行更新\n",
    " \n",
    "        if step % 50 == 0:\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].numpy()  # torch.max(test_out,1)返回的是test_out中每一行最大的数)\n",
    "                                                                # 返回的形式为torch.return_types.max(\n",
    "                                                                #           values=tensor([0.7000, 0.9000]),\n",
    "                                                                #           indices=tensor([2, 2]))\n",
    "                                                                # 后面的[1]代表获取indices\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n",
    " \n",
    " \n",
    "# 打印前十个测试结果和真实结果进行对比\n",
    "test_output = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbdb0af",
   "metadata": {},
   "source": [
    "### SGD-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "752fed80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.0242\n",
      "Epoch:  0 | train loss: 0.0265\n",
      "Epoch:  0 | train loss: 0.0045\n",
      "Epoch:  0 | train loss: 0.0529\n",
      "Epoch:  0 | train loss: 0.0363\n",
      "Epoch:  0 | train loss: 0.0063\n",
      "Epoch:  0 | train loss: 0.0937\n",
      "Epoch:  0 | train loss: 0.0706\n",
      "Epoch:  0 | train loss: 0.0135\n",
      "Epoch:  0 | train loss: 0.0084\n",
      "Epoch:  0 | train loss: 0.0038\n",
      "Epoch:  0 | train loss: 0.0059\n",
      "Epoch:  0 | train loss: 0.0231\n",
      "Epoch:  0 | train loss: 0.0129\n",
      "Epoch:  0 | train loss: 0.0309\n",
      "Epoch:  0 | train loss: 0.0122\n",
      "Epoch:  0 | train loss: 0.0036\n",
      "Epoch:  0 | train loss: 0.0110\n",
      "Epoch:  0 | train loss: 0.0458\n",
      "Epoch:  0 | train loss: 0.0034\n",
      "Epoch:  0 | train loss: 0.0059\n",
      "Epoch:  0 | train loss: 0.0745\n",
      "Epoch:  0 | train loss: 0.0289\n",
      "Epoch:  0 | train loss: 0.0357\n",
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(cnn.parameters(),lr=LR, momentum=0.9) # 定义优化器\n",
    "loss_func = nn.CrossEntropyLoss() # 定义损失函数\n",
    " \n",
    "for epoch in range(EPOCH):\n",
    " \n",
    "    for step,(batch_x,batch_y) in enumerate(train_loader):\n",
    "        pred_y = cnn(batch_x)\n",
    "        loss = loss_func(pred_y,batch_y)\n",
    "        optimizer.zero_grad() # 清空上一层梯度\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新优化器的学习率，一般按照epoch为单位进行更新\n",
    " \n",
    "        if step % 50 == 0:\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].numpy()  # torch.max(test_out,1)返回的是test_out中每一行最大的数)\n",
    "                                                                # 返回的形式为torch.return_types.max(\n",
    "                                                                #           values=tensor([0.7000, 0.9000]),\n",
    "                                                                #           indices=tensor([2, 2]))\n",
    "                                                                # 后面的[1]代表获取indices\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n",
    " \n",
    " \n",
    "# 打印前十个测试结果和真实结果进行对比\n",
    "test_output = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1adef4",
   "metadata": {},
   "source": [
    "### NAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d44c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.0348\n",
      "Epoch:  0 | train loss: 0.0679\n",
      "Epoch:  0 | train loss: 0.0084\n",
      "Epoch:  0 | train loss: 0.0175\n",
      "Epoch:  0 | train loss: 0.0277\n",
      "Epoch:  0 | train loss: 0.0159\n",
      "Epoch:  0 | train loss: 0.0111\n",
      "Epoch:  0 | train loss: 0.0153\n",
      "Epoch:  0 | train loss: 0.0116\n",
      "Epoch:  0 | train loss: 0.0022\n",
      "Epoch:  0 | train loss: 0.0047\n",
      "Epoch:  0 | train loss: 0.0055\n",
      "Epoch:  0 | train loss: 0.0037\n",
      "Epoch:  0 | train loss: 0.0274\n",
      "Epoch:  0 | train loss: 0.0155\n",
      "Epoch:  0 | train loss: 0.0882\n",
      "Epoch:  0 | train loss: 0.0111\n",
      "Epoch:  0 | train loss: 0.0129\n",
      "Epoch:  0 | train loss: 0.1160\n",
      "Epoch:  0 | train loss: 0.0247\n",
      "Epoch:  0 | train loss: 0.0587\n",
      "Epoch:  0 | train loss: 0.0425\n",
      "Epoch:  0 | train loss: 0.0020\n",
      "Epoch:  0 | train loss: 0.0032\n",
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(cnn.parameters(),lr=LR, momentum=0.9,nesterov=True) # 定义优化器\n",
    "loss_func = nn.CrossEntropyLoss() # 定义损失函数\n",
    " \n",
    "for epoch in range(EPOCH):\n",
    " \n",
    "    for step,(batch_x,batch_y) in enumerate(train_loader):\n",
    "        pred_y = cnn(batch_x)\n",
    "        loss = loss_func(pred_y,batch_y)\n",
    "        optimizer.zero_grad() # 清空上一层梯度\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新优化器的学习率，一般按照epoch为单位进行更新\n",
    " \n",
    "        if step % 50 == 0:\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].numpy()  # torch.max(test_out,1)返回的是test_out中每一行最大的数)\n",
    "                                                                # 返回的形式为torch.return_types.max(\n",
    "                                                                #           values=tensor([0.7000, 0.9000]),\n",
    "                                                                #           indices=tensor([2, 2]))\n",
    "                                                                # 后面的[1]代表获取indices\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n",
    " \n",
    " \n",
    "# 打印前十个测试结果和真实结果进行对比\n",
    "test_output = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c3f35d",
   "metadata": {},
   "source": [
    "## Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3defe682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.0019\n",
      "Epoch:  0 | train loss: 0.0148\n",
      "Epoch:  0 | train loss: 0.0064\n",
      "Epoch:  0 | train loss: 0.0221\n",
      "Epoch:  0 | train loss: 0.0038\n",
      "Epoch:  0 | train loss: 0.0312\n",
      "Epoch:  0 | train loss: 0.0347\n",
      "Epoch:  0 | train loss: 0.0158\n",
      "Epoch:  0 | train loss: 0.0020\n",
      "Epoch:  0 | train loss: 0.0872\n",
      "Epoch:  0 | train loss: 0.0218\n",
      "Epoch:  0 | train loss: 0.0405\n",
      "Epoch:  0 | train loss: 0.0017\n",
      "Epoch:  0 | train loss: 0.0030\n",
      "Epoch:  0 | train loss: 0.0502\n",
      "Epoch:  0 | train loss: 0.0018\n",
      "Epoch:  0 | train loss: 0.0041\n",
      "Epoch:  0 | train loss: 0.0145\n",
      "Epoch:  0 | train loss: 0.0045\n",
      "Epoch:  0 | train loss: 0.0052\n",
      "Epoch:  0 | train loss: 0.0064\n",
      "Epoch:  0 | train loss: 0.0013\n",
      "Epoch:  0 | train loss: 0.0360\n",
      "Epoch:  0 | train loss: 0.0174\n",
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adagrad(cnn.parameters(),lr=LR) # 定义优化器\n",
    "loss_func = nn.CrossEntropyLoss() # 定义损失函数\n",
    " \n",
    "for epoch in range(EPOCH):\n",
    " \n",
    "    for step,(batch_x,batch_y) in enumerate(train_loader):\n",
    "        pred_y = cnn(batch_x)\n",
    "        loss = loss_func(pred_y,batch_y)\n",
    "        optimizer.zero_grad() # 清空上一层梯度\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新优化器的学习率，一般按照epoch为单位进行更新\n",
    " \n",
    "        if step % 50 == 0:\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].numpy()  # torch.max(test_out,1)返回的是test_out中每一行最大的数)\n",
    "                                                                # 返回的形式为torch.return_types.max(\n",
    "                                                                #           values=tensor([0.7000, 0.9000]),\n",
    "                                                                #           indices=tensor([2, 2]))\n",
    "                                                                # 后面的[1]代表获取indices\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n",
    " \n",
    " \n",
    "# 打印前十个测试结果和真实结果进行对比\n",
    "test_output = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb4880",
   "metadata": {},
   "source": [
    "## RMSProp (torch版本低导致，有兴趣自行测试)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f601c7cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.optim' has no attribute 'RMSProp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c096d214b461>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSProp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.99\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 定义优化器\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 定义损失函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.optim' has no attribute 'RMSProp'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.RMSprop(cnn.parameters(),lr=0.001, alpha=0.9) # 定义优化器\n",
    "loss_func = nn.CrossEntropyLoss() # 定义损失函数\n",
    " \n",
    "for epoch in range(EPOCH):\n",
    " \n",
    "    for step,(batch_x,batch_y) in enumerate(train_loader):\n",
    "        pred_y = cnn(batch_x)\n",
    "        loss = loss_func(pred_y,batch_y)\n",
    "        optimizer.zero_grad() # 清空上一层梯度\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新优化器的学习率，一般按照epoch为单位进行更新\n",
    " \n",
    "        if step % 50 == 0:\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].numpy()  # torch.max(test_out,1)返回的是test_out中每一行最大的数)\n",
    "                                                                # 返回的形式为torch.return_types.max(\n",
    "                                                                #           values=tensor([0.7000, 0.9000]),\n",
    "                                                                #           indices=tensor([2, 2]))\n",
    "                                                                # 后面的[1]代表获取indices\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n",
    " \n",
    " \n",
    "# 打印前十个测试结果和真实结果进行对比\n",
    "test_output = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d187f3",
   "metadata": {},
   "source": [
    "## Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "041bfa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.0145\n",
      "Epoch:  0 | train loss: 0.0014\n",
      "Epoch:  0 | train loss: 0.0084\n",
      "Epoch:  0 | train loss: 0.0458\n",
      "Epoch:  0 | train loss: 0.0735\n",
      "Epoch:  0 | train loss: 0.0078\n",
      "Epoch:  0 | train loss: 0.0141\n",
      "Epoch:  0 | train loss: 0.0337\n",
      "Epoch:  0 | train loss: 0.0274\n",
      "Epoch:  0 | train loss: 0.0098\n",
      "Epoch:  0 | train loss: 0.0009\n",
      "Epoch:  0 | train loss: 0.0048\n",
      "Epoch:  0 | train loss: 0.0045\n",
      "Epoch:  0 | train loss: 0.0023\n",
      "Epoch:  0 | train loss: 0.0598\n",
      "Epoch:  0 | train loss: 0.0082\n",
      "Epoch:  0 | train loss: 0.0009\n",
      "Epoch:  0 | train loss: 0.0577\n",
      "Epoch:  0 | train loss: 0.0039\n",
      "Epoch:  0 | train loss: 0.0447\n",
      "Epoch:  0 | train loss: 0.0019\n",
      "Epoch:  0 | train loss: 0.0038\n",
      "Epoch:  0 | train loss: 0.0063\n",
      "Epoch:  0 | train loss: 0.0139\n",
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adadelta(cnn.parameters(),lr=LR) # 定义优化器\n",
    "loss_func = nn.CrossEntropyLoss() # 定义损失函数\n",
    " \n",
    "for epoch in range(EPOCH):\n",
    " \n",
    "    for step,(batch_x,batch_y) in enumerate(train_loader):\n",
    "        pred_y = cnn(batch_x)\n",
    "        loss = loss_func(pred_y,batch_y)\n",
    "        optimizer.zero_grad() # 清空上一层梯度\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新优化器的学习率，一般按照epoch为单位进行更新\n",
    " \n",
    "        if step % 50 == 0:\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].numpy()  # torch.max(test_out,1)返回的是test_out中每一行最大的数)\n",
    "                                                                # 返回的形式为torch.return_types.max(\n",
    "                                                                #           values=tensor([0.7000, 0.9000]),\n",
    "                                                                #           indices=tensor([2, 2]))\n",
    "                                                                # 后面的[1]代表获取indices\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n",
    " \n",
    " \n",
    "# 打印前十个测试结果和真实结果进行对比\n",
    "test_output = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c30d7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e60c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02194c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba714d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb2964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478ab18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dcca82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f24c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c10953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2981a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f44c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38a7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fdd4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c0bb32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be4998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3320bd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abec1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ceb6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e3205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c5254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9cd30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f1952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476b8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ece7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63bdc28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b3312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
